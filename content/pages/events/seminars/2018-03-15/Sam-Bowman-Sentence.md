---
date: 2018-03-15
title: "Sentence Understanding with Neural Networks and Natural Language Inference"
lecturer: "Sam Bowman"
duration: "2 hours"
venue: "Gothenburg"
slides: ./1684992_go--teborg-ii.pdf
---



Artificial neural networks now represent the state of the art in most large-scale applied language understanding tasks. This talk presents a few methods and results, organized around the task of recognizing textual entailment, which measure the degree to which these models can or do learn something resembling compositional semantics. I discuss experiments on artificial data and on a hand-built million-example corpus of natural data (SNLI/MultiNLI), and report encouraging results.

ReferencesBowman, Samuel R., Christopher Potts, and Christopher D. Manning. "Recursive neural networks can learn logical semantics." arXiv preprint arXiv:1406.1827 (2014).




